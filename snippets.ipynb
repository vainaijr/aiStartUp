{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snippets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "-_nVeZK9vZ8m",
        "nokBXc1CwQ7k",
        "6qj_CkF1gDUD",
        "75fczkzki9Fp",
        "ej3Uwo_smfTs",
        "I6_6BgQuzfuP",
        "Aw1ze6i3zpfR",
        "Wlndqa9tLrGB",
        "r3hEzo0EMcvz",
        "YXnd_IupPf5t",
        "y5Mal_jfXqjw",
        "G-VYs_PvZ5aj",
        "iPT2g2cVeucl",
        "os_xISCFfTU8",
        "2eubf-YzfcJo",
        "8kbPVTSzfesP",
        "U5S9dsaBgaah",
        "jrZvY9Jugo4O",
        "K4EESxOmg0zv",
        "DJmW7gkJg8tj",
        "cXgyVNuXhBzF",
        "Jwwc34-a2F79",
        "NVqByHwi3aMZ",
        "-ovyMKbT81DU",
        "LrwUjNhx0Tfn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vainaijr/aiStartUp/blob/master/snippets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ep1ZiMgDZVb",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PldrprjiDeZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, unicode_literals, division\n",
        "from IPython.core.debugger import set_trace\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import Compose, RandomHorizontalFlip, RandomResizedCrop, ToTensor, Normalize\n",
        "from torchvision.transforms import CenterCrop, Resize, ColorJitter\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import copy\n",
        "import glob\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "\n",
        "print(\"CUDA available: \", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_nVeZK9vZ8m",
        "colab_type": "text"
      },
      "source": [
        "# LeNet model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwNqwG3hvcNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M9e4gt8wC6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nokBXc1CwQ7k",
        "colab_type": "text"
      },
      "source": [
        "# MNIST dataset, dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXZesVXdwVDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train dataset\n",
        "train_loader = DataLoader(datasets.MNIST('./', train=True, download=True,\n",
        "                                                         transform=Compose([\n",
        "                                                             ToTensor(),\n",
        "                                                             Normalize((0.1307,), (0.3081,))\n",
        "                                                         ])), batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "# test dataset\n",
        "test_loader = DataLoader(datasets.MNIST('./', train=False, download=False,\n",
        "                                                         transform=Compose([\n",
        "                                                             ToTensor(),\n",
        "                                                             Normalize((0.1307,), (0.3081,))\n",
        "                                                         ])), batch_size=1, shuffle=True, num_workers=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVFI3iDiw0hA",
        "colab_type": "text"
      },
      "source": [
        "# CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNlpQ5Z1w3dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"CUDA available: \", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHRC5Uqd_KGx",
        "colab_type": "text"
      },
      "source": [
        "# transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si7DDADJ_MLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = transforms.Compose([\n",
        "    transforms.Resize(imsize),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_transform = Compose([\n",
        "    RandomCrop(200),\n",
        "    RandomHorizontalFlip(),\n",
        "    ColorJitter(),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "data_transforms = {\n",
        "    \n",
        "  'train' : Compose([\n",
        "    RandomResizedCrop(input_size),\n",
        "    RandomHorizontalFlip(),\n",
        "    ColorJitter(),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "  ]),\n",
        "  'val' : Compose([\n",
        "      Resize(input_size),\n",
        "      CenterCrop(input_size),\n",
        "      ToTensor(),\n",
        "      Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])    \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qj_CkF1gDUD",
        "colab_type": "text"
      },
      "source": [
        "# unicodeToAscii"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukG38gzUgKJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# turn a Unicode string to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "      and c in all_letters\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75fczkzki9Fp",
        "colab_type": "text"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zi_uWuOi-Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(RNN, self).__init__()\n",
        "    \n",
        "    self.hidden_size = hidden_size\n",
        "    self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    combined = torch.cat((input, hidden), 1)\n",
        "    hidden = self.i2h(combined)\n",
        "    output = self.i2o(combined)\n",
        "    output = self.softmax(output)\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej3Uwo_smfTs",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuobQF5Gmhas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6_6BgQuzfuP",
        "colab_type": "text"
      },
      "source": [
        "# Lang"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIxw044TzgvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "    self.n_words = 2 # count SOS and EOS\n",
        "    \n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "  \n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw1ze6i3zpfR",
        "colab_type": "text"
      },
      "source": [
        "# normalizeString"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZso-1g7zr0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-z.!?]\", r\" \", s)\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlndqa9tLrGB",
        "colab_type": "text"
      },
      "source": [
        "# EncoderRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y4xjASwLsym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence.\n",
        "# for every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next\n",
        "# input word.\n",
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3hEzo0EMcvz",
        "colab_type": "text"
      },
      "source": [
        "# DecoderRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lia56vWzMesF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "  def forward(self, input, hidden):\n",
        "    output = self.embedding(input).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXnd_IupPf5t",
        "colab_type": "text"
      },
      "source": [
        "# AttnDecoderRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyMbWoVLPhxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "    super(AttnDecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.dropout_p = dropout_p\n",
        "    self.max_length = max_length\n",
        "    \n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "    self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "  \n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    embedded = self.dropout(embedded)\n",
        "    \n",
        "    attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "    \n",
        "    output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "    output = self.attn_combine(output).unsqueeze(0)\n",
        "    \n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    \n",
        "    output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "    return output, hidden, attn_weights\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Mal_jfXqjw",
        "colab_type": "text"
      },
      "source": [
        "# timeSince"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFS1uBxBXvLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def asMinutes(s):\n",
        "  m = math.floor(s / 60)\n",
        "  s -= m * 60\n",
        "  return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s / (percent)\n",
        "  rs = es - s\n",
        "  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-VYs_PvZ5aj",
        "colab_type": "text"
      },
      "source": [
        "# plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rdlMm4jZ73t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.switch_backend('agg')\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  loc = ticker.MultipleLocator(base=0.2) # this locator puts ticks at regulate intervals\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)\n",
        "  \n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.title(\"Test dataset 'Horses'\")\n",
        "plt.imshow(test_A[0])\n",
        "plt.subplot(122)\n",
        "plt.title(\"Test dataset 'Zebras'\")\n",
        "plt.imshow(test_B[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPT2g2cVeucl",
        "colab_type": "text"
      },
      "source": [
        "# BiRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D-gWuc4ev-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recurrent Neural Networks (many to one)\n",
        "class BiRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(BiRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "    # torch.nn.LSTM(*args, **kwargs)\n",
        "    # applies a multi layer long shot term memory RNN to an input sequence\n",
        "    \n",
        "    # parameters\n",
        "    # input_size - the number of expected features in the input x\n",
        "    # hidden_size - the number of features in the hidden state h\n",
        "    # num_layers - number of recurrent layers, example, setting num_layers = 2 would mean stacking two LSTMs together\n",
        "    # to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results\n",
        "    # default: 1\n",
        "    # bias - if False, then the layer does not use bias weights, default: True\n",
        "    # batch_first - if True, then the input and output tensors are provided as (batch, seq, feature), default: False\n",
        "    # dropout - if non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer,\n",
        "    # with dropout probability equal to dropout, default: 0\n",
        "    # bidirectional - if True, becomes a bidirectional LSTM, default: False\n",
        "    \n",
        "    # inputs - input, (h_0, c_0)\n",
        "    \n",
        "    # input of shape (seq_len, batch, input_size) - tensor containing the features of the input sequence, the input \n",
        "    # can also be a packed variable length sequence\n",
        "    \n",
        "    # h_0 of shape (num_layers*num_directions, batch, hidden_size) - tensor containing the initial hidden state for \n",
        "    # each element in the batch, if the LSTM is bidirectional, num_directions should be 2, else it should be 1\n",
        "    \n",
        "    # c_0 of shape (num_layers*num_directions, batch, hidden_size) - tensor containing the initial cell state for each\n",
        "    # element in the batch\n",
        "    \n",
        "    # if (h_0, c_0) is not provided, both h_0 and c_0 default to zero\n",
        "    \n",
        "    # outputs - output, (h_n, c_n)\n",
        "    \n",
        "    # output of shape (seq_len, batch, num_directions*hidden_size) - tensor containing the ouput features (h_t) from\n",
        "    # the last layer of the LSTM, for each t\n",
        "    \n",
        "    # h_n of shape (num_layers*num_directions, batch, hidden_size) - tensor containing the hidden state for \n",
        "    # t = seq_len\n",
        "    \n",
        "    # c_n of shape (num_layers*num_directions, batch, hidden_size) - tensor containing the cell state for t = seq_len\n",
        "    \n",
        "    self.fc = nn.Linear(hidden_size*2, num_classes)\n",
        "    # torch.nn.Linear(in_features, out_features, bias=True)\n",
        "    # applies a linear transformation to the incoming data\n",
        "\n",
        "    # parameters\n",
        "    # in_feature - size of each input sample\n",
        "    # out_feature - size of each output sample\n",
        "    # bias - if set to False, the layer will not learn an additive bias, default: True\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # set initial hidden and cell states\n",
        "    h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
        "    # torch.zeros(*sizes, out=None, layout=torch.strided, device=None, requires_grad=False)\n",
        "    # returns a tensor filled with the scalar value 0, with the shape defined by the variable argument sizes\n",
        "\n",
        "    # parameters\n",
        "    # sizes - a sequence of integers defining the shape of the output tensor, can be a variable number of argumentss\n",
        "    # or a collection like a list or tuple\n",
        "    # out - the output tensor\n",
        "    # dtype - the desired data type of returned tensor, default: if None, uses a global default\n",
        "    # layout - the desired layout of returned tensor, default: torch.strided\n",
        "    # device - the desired device of returned tensor\n",
        "    # requires_grad - if autograd should record operations on the returned tensor, default: False\n",
        "\n",
        "    c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
        "\n",
        "    # forward propagate LSTM\n",
        "    out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "    # outputs - output, (h_n, c_n)\n",
        "\n",
        "    # output of shape (seq_len, batch, num_directions*hidden_size) - tensor containing the ouput features (h_t) from\n",
        "    # the last layer of the LSTM, for each t\n",
        "\n",
        "    # h_n of shape (num_layers*num_directions, batch, hidden_size) - tensor containing the hidden state for \n",
        "    # t = seq_len\n",
        "\n",
        "    # c_n of shape (num_layers*num_directions, batch, hidden_size) - tensor containing the cell state for \n",
        "    # t = seq_len\n",
        "\n",
        "    # decode the hidden state of the last time step\n",
        "    out = self.fc(out[:, -1, :])\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os_xISCFfTU8",
        "colab_type": "text"
      },
      "source": [
        "# loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDevrOldfVQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss() # loss function, example, MSELoss, L1Loss, CTCLoss, NLLLoss, PoissonNLLLoss, KLDivLoss,BCELoss,\n",
        "# BCEWithLogitsLoss, MarginRankingLoss, HingeEmbeddingLoss, MultiLabelMarginLoss, SmoothL1Loss, SoftMarginLoss, \n",
        "# MultiLabelSoftMarginLoss, CosineEmbeddingLoss, MultiMarginLoss, TripletMarginLoss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # optimizer, example, Adadelta, Adagrad, SparseAdam, Adamax,\n",
        "# ASGD, LBFGS, RMSprop, Rprop, SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eubf-YzfcJo",
        "colab_type": "text"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5kwAGuDfdQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # move tensors to the configured device\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        # reshape(*shape) -> Tensor\n",
        "        # returns a tensor with the same data and number of elements as self but with the specified shape.\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # backward and optimize\n",
        "        optimizer.zero_grad() # set gradients of all model parameters to zero\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kbPVTSzfesP",
        "colab_type": "text"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNVQ5H_zffkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        \n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1) \n",
        "        \n",
        "        # torch.max(input, dim, keepdim=False, out=None) returns a namedtuple (values, indices) where values is the maximum\n",
        "        # value of each row of the input tensor in the given dimension dim, and indices is the index location of each maximum\n",
        "        # value found (argmax).\n",
        "        # If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of\n",
        "        # size 1\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        \n",
        "        correct += (predicted == labels).sum().item() \n",
        "        \n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100*correct / total))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5S9dsaBgaah",
        "colab_type": "text"
      },
      "source": [
        "# make_grid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pqEXKI0gbw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images from A\")\n",
        "plt.imshow(vutils.make_grid(real_batch['A'][:64], padding=2, normalize=True).cpu().numpy().transpose(1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrZvY9Jugo4O",
        "colab_type": "text"
      },
      "source": [
        "# Ignite import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I9H854Igqjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignite is a high level library to help with training neural networks in PyTorch, it comes with an Engine to setup\n",
        "# a training loop, various metrics, handlers\n",
        "!pip install ignite\n",
        "from ignite.engine import Engine, Events \n",
        "# Engine - runs a given process_function over each batch of a dataset, emitting events as it goes\n",
        "# Events - allows users to attach functions to an Engine to fire functions at a specific event, example: \n",
        "# EPOCH_COMPLETED, ITERATION_STARTED etc.\n",
        "\n",
        "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
        "# Accuracy - metric to calculate accuracy over a dataset, for binary, multiclass, multilabel cases\n",
        "# Loss - general metric that takes a loss function as a parameter, calculate loss over a dataset\n",
        "# RunningAverage - general metric to attach to Engine during training\n",
        "\n",
        "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
        "# ModelCheckpoint - handler to checkpoint models\n",
        "# EarlyStopping - handler to stop training based on a score function\n",
        "\n",
        "from ignite.contrib.handlers import ProgressBar\n",
        "# ProgressBar - handler to create a tqdm progress bar, tqdm means progress in Arabic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4EESxOmg0zv",
        "colab_type": "text"
      },
      "source": [
        "# TextCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK75h1Meg2Ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TextCNN model\n",
        "# the model works for variable text lengths, we embed the words of a sentence, use convolutions, maxpooling\n",
        "# and concatenation to embed the sentence as a single vector\n",
        "# the single vector is passed through a fully connected layer with sigmoid to output a single value\n",
        "# this value can be interpreted as the probability a sentence is positive (closer to 1) or negative (closer to 0)\n",
        "\n",
        "# the minimum length of text expected by the model is the size of the smallest kernel size of the model\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, kernel_sizes, num_filters, num_classes, d_prob, mode):\n",
        "    super(TextCNN, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.kernel_sizes = kernel_sizes\n",
        "    self.num_filters = num_filters\n",
        "    self.num_classes = num_classes\n",
        "    self.d_prob = d_prob\n",
        "    self.mode = mode\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=1)\n",
        "    self.load_embeddings()\n",
        "    self.conv = nn.ModuleList([nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=k,\n",
        "                                        stride=1) for k in kernel_sizes])\n",
        "    self.dropout = nn.Dropout(d_prob)\n",
        "    self.fc = nn.Linear(len(kernel_sizes)*num_filters, num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    batch_size, sequence_length = x.shape\n",
        "    x = self.embedding(x).transpose(1, 2)\n",
        "    x = [F.relu(conv(x)) for conv in self.conv]\n",
        "    x = [F.max_pool1d(c, c.size(-1)).squeeze(dim=-1) for c in x]\n",
        "    x = torch.cat(x, dim=1)\n",
        "    x = self.fc(self.dropout(x))\n",
        "    return torch.sigmoid(x).squeeze()\n",
        "  \n",
        "  def load_embeddings(self):\n",
        "    if 'static' in self.mode:\n",
        "      self.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
        "      if 'non' not in self.mode:\n",
        "        self.embedding.weight.data.requires_grad = False\n",
        "        print('Loaded pretrained embeddings, weights are not trainable')\n",
        "      else:\n",
        "        self.embedding.weight.data.requires_grad = True\n",
        "        print('Loaded pretrained embeddings, weights are trainable')\n",
        "      \n",
        "    elif self.mode == 'rand':\n",
        "      print('Randoml initialized embeddings are used')\n",
        "    else:\n",
        "      raise ValueError('Unexpected value of mode')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJmW7gkJg8tj",
        "colab_type": "text"
      },
      "source": [
        "# Ignite process_function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr7oIZEUg-4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training and evaluating using Ignite\n",
        "# Ignite's Engine allows user to define a process_function a given batch, this is applied to all the batches of \n",
        "# the dataset, this is a general class that can be applied to train and validate models, a process_function\n",
        "# has two parameters, engine and batch\n",
        "\n",
        "# the function of the trainer\n",
        "# sets model in train mode\n",
        "# sets the gradient of the optimizer to zero\n",
        "# generate x and y from batch\n",
        "# performs a forward pass to calculate y_pred using model and x\n",
        "# calculates loss using y_pred and y\n",
        "# performs a backward pass using loss to calculate gradients for the model parameters\n",
        "# model parameters are optimized using gradients and optimizer\n",
        "# returns scalar loss\n",
        "\n",
        "def process_function(engine, batch):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  x, y = batch.text, batch.label\n",
        "  y_pred = model(x)\n",
        "  loss = criterion(y_pred, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXgyVNuXhBzF",
        "colab_type": "text"
      },
      "source": [
        "# Ignite eval_function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8ZoZE-IhDhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluator engine - process_function\n",
        "\n",
        "# similar to the training process function, we setup a function to evaluate a single batch\n",
        "\n",
        "# eval_function\n",
        "# sets model in eval mode\n",
        "# generates x and y from batch\n",
        "# with torch.no_grad(), no gradients are calculated for any succeeding steps\n",
        "# performs a forward pass on the model to calculate y_pred based on model and x\n",
        "# returns y_pred and y\n",
        "\n",
        "# Ignite suggests attaching metrics to evaluators and not trainers\n",
        "\n",
        "# all metrics in Ignite require y_pred and y as outputs of the function attached to the Engine\n",
        "\n",
        "def eval_function(engine, batch):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    x, y = batch.text, batch.label\n",
        "    y_pred = model(x)\n",
        "    return y_pred, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwwc34-a2F79",
        "colab_type": "text"
      },
      "source": [
        "# CustomDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDfZeD4U2Iol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  \n",
        "  def __len__(self):\n",
        "    return 0\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVqByHwi3aMZ",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo_nLRFV3cw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training helpers\n",
        "\n",
        "# list(get_trainable(model.parameters()))\n",
        "def get_trainable(model_params):\n",
        "  return (p for p in model_params if p.requires_grad)\n",
        "\n",
        "# list(get_frozen(model.parameters()))\n",
        "def get_frozen(model_params):\n",
        "  return (p for p in model_params if not p.requires_grad)\n",
        "\n",
        "# all_trainable(model.parameters())\n",
        "def all_trainable(model_params):\n",
        "  return all(p.requires_grad for p in model.params)\n",
        "\n",
        "# all_frozen(model.parameters())\n",
        "def all_frozen(model_params):\n",
        "  return all(not p.requires_grad for p in model.params)\n",
        "\n",
        "def freeze_all(model_params):\n",
        "  for param in model_params:\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ovyMKbT81DU",
        "colab_type": "text"
      },
      "source": [
        "# pretrainedmodels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfUGpT8V823d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pretrainedmodels\n",
        "import pretrainedmodels\n",
        "print(pretrainedmodels.model_names)\n",
        "\n",
        "model_name = 'nasnetalarge' # could be fbresnet152 or inceptionresnetv2\n",
        "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrwUjNhx0Tfn",
        "colab_type": "text"
      },
      "source": [
        "# train_model_helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QE_9BGv0XIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "  since = time.time()\n",
        "  \n",
        "  val_acc_history = []\n",
        "  \n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train() # set model to training mode\n",
        "      else:\n",
        "        model.eval() # set model to eval mode\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      # iterate over data\n",
        "      for inputs, labels in dataloader[phase]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          # get model outputs and calculate loss\n",
        "          # special case for inception because in training it has an auxiliary output.\n",
        "          # in train mode we calculate the loss by summing the final output and the auxiliary output but in testing\n",
        "          # we only consider the final output.\n",
        "          if is_inception and phase == 'train':\n",
        "            outputs, aux_outputs = model(inputs)\n",
        "            loss1 = criterion(outputs, labels)\n",
        "            loss2 = criterion(aux_outputs, labels)\n",
        "            loss = loss1 + 0.4*loss2\n",
        "          else:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          # backward + optimize only if in training phase\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    # deep copy the model\n",
        "    if phase == 'val' and epoch_acc > best_acc:\n",
        "      best_acc = epoch_acc\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    if phase == 'val':\n",
        "      val_acc_history.append(epoch_acc)\n",
        "\n",
        "  print()\n",
        "  \n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapse // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "  \n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4W5iU2RkhwT",
        "colab_type": "text"
      },
      "source": [
        "# datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmyZmuDkjzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train',\n",
        "                                                                                                   'val']}\n",
        "\n",
        "# create training and vaildation dataloaders\n",
        "dataloaders_dict = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in\n",
        "                  ['train', 'val']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHPmxCtHqjiV",
        "colab_type": "text"
      },
      "source": [
        "# plot_compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq6fax2mqkr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1, num_epochs+1), ohist, label=\"Pretrained\")\n",
        "plt.plot(range(1, num_epochs+1), shist, label=\"Scratch\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipyk8gJ3AQYE",
        "colab_type": "text"
      },
      "source": [
        "# STN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeyUfA7bAR1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "    \n",
        "    # Spatial transformer localization-network\n",
        "    self.localization = nn.Sequential(\n",
        "        nn.Conv2d(1, 8, kernel_size=7),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(8, 10, kernel_size=5),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "    \n",
        "    # regressor for the 3 * 2 affine matrix\n",
        "    self.fc_loc = nn.Sequential(\n",
        "        nn.Linear(10 * 3 * 3, 32),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(32, 3 * 2)\n",
        "    )\n",
        "    \n",
        "    # initialize the weights/bias with identity transformation\n",
        "    self.fc_loc[2].weight.data.zero_()\n",
        "    self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
        "    \n",
        "  # spatial transformer network forward function\n",
        "  def stn(self, x):\n",
        "    xs = self.localization(x)\n",
        "    xs = xs.view(-1, 10 * 3 * 3)\n",
        "    theta = self.fc_loc(xs)\n",
        "    theta = theta.view(-1, 2, 3)\n",
        "    \n",
        "    grid = F.affine_grid(theta, x.size())\n",
        "    x = F.grid_sample(x, grid)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # transform the input\n",
        "    x = self.stn(x)\n",
        "    \n",
        "    # perform forward pass\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "  \n",
        "model = Net().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfo9ULtNC9E4",
        "colab_type": "text"
      },
      "source": [
        "# train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIrTorbiC-lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  # total_step = len(train_loader)\n",
        "  for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "    # move tensors to the configured device\n",
        "    images = images.to(device)\n",
        "    # reshape(*shape) -> Tensor\n",
        "    # returns a tensor with the same data and number of elements as self but with the specified shape.\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = F.nll_loss(outputs, labels)\n",
        "\n",
        "    # backward and optimize\n",
        "    optimizer.zero_grad() # set gradients of all model parameters to zero\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (batch_idx) % 500 == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(images), \n",
        "                                                                       len(train_loader.dataset), \n",
        "                                                                       100. * batch_idx / len(train_loader), \n",
        "                                                                       loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Q8TZDeDBlh",
        "colab_type": "text"
      },
      "source": [
        "# test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEdBjQeCDC3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      test_loss = 0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = model(images)\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1) \n",
        "\n",
        "          test_loss += F.nll_loss(outputs, labels, size_averag=False).item()\n",
        "\n",
        "          pred = output.max(1, keepdim=True)[1]\n",
        "\n",
        "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "      \n",
        "      test_loss /= len(test_loader.dataset)\n",
        "      \n",
        "      print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct,\n",
        "                                                                                  len(test_loader.dataset),\n",
        "                                                                                  100. * correct / \n",
        "                                                                                  len(test_loader.dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eve2ggA_DnPk",
        "colab_type": "text"
      },
      "source": [
        "# tensor to numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es-6eB4bDo0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_np(inp):\n",
        "  inp = inp.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  inp = std * inp + mean\n",
        "  inp = np.clip(inp, 0, 1)\n",
        "  return inp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr81DW_iE0mA",
        "colab_type": "text"
      },
      "source": [
        "# visualize stn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8yjrepRE19Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_stn():\n",
        "  with torch.no_grad():\n",
        "    # get a batch of training data\n",
        "    data = next(iter(test_loader))[0].to(device)\n",
        "    \n",
        "    input_tensor = data.cpu()\n",
        "    transformed_input_tensor = model.stn(data).cpu()\n",
        "    \n",
        "    in_grid = convert_image_np(make_grid(input_tensor))\n",
        "    \n",
        "    out_grid = convert_image_np(make_grid(transformed_input_tensor))\n",
        "    \n",
        "    # plot the results side by side\n",
        "    f, axarr = plt.subplots(1, 2)\n",
        "    axarr[0].imshow(in_grid)\n",
        "    axarr[0].set_title('Dataset Images')\n",
        "    \n",
        "    axarr[1].imshow(out_grid)\n",
        "    axarr[1].set_title('Transformed Images')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}